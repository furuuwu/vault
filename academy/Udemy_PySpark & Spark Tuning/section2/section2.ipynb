{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD0iK3cq3hNh",
        "outputId": "a9a34e3a-b884-4170-e71b-10de2274d871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Spark\n",
        "\n",
        "old_way = False\n",
        "if old_way:\n",
        "  from pyspark import SparkContext, SparkConf\n",
        "  conf = SparkConf().setAppName(\"Archive_PySpark\").setMaster(\"local[*]\")\n",
        "  sc = SparkContext(conf=conf)\n",
        "else:\n",
        "  from pyspark.sql import SparkSession\n",
        "  # Start a Spark session\n",
        "  spark = SparkSession.builder \\\n",
        "    .appName(\"ArXiv Analysis\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "k58PUSLG3to1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and Load Data to Spark\n",
        "# Data source: https://www.kaggle.com/Cornell-University/arxiv/version/1\n",
        "# https://www.kaggle.com/datasets/Cornell-University/arxiv/data"
      ],
      "metadata": {
        "id": "7FzwVB9X3xkO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame"
      ],
      "metadata": {
        "id": "FdXLcCjJ-LK4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "using_GoogleColab = True\n",
        "if using_GoogleColab:\n",
        "  # to work with files inside Google Colab,\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  # and right-click copy path of the files you want\n",
        "else:\n",
        "  # idk man\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq9iWERMCz1i",
        "outputId": "14ec7883-f756-4d60-e4f0-90b5fbb89716"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON file\n",
        "# data: DataFrame = spark.read.json(\"path/to/arxiv-metadata.json\")\n",
        "data: DataFrame = spark.read.json(\"drive/MyDrive/Colab Notebooks/arxiv-metadata-oai-snapshot.json\")"
      ],
      "metadata": {
        "id": "4bo-5Tls5ytI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col"
      ],
      "metadata": {
        "id": "zq-zloK-6sW1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".withColumn() - Returns a new DataFrame by adding a column or replacing the existing column that has the same name.\n",
        "\n",
        "explode() - Returns a new row for each element in the given array or map. Uses the default column name col for elements in the array and key and value for elements in the map unless specified otherwise\n",
        "\n",
        "col() - Returns a pyspark.sql.Column based on the given column name"
      ],
      "metadata": {
        "id": "uOP1CwdD_dqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explode the versions to access version 1 details\n",
        "data_with_versions = data.withColumn(\"version\", explode(col(\"versions\")))"
      ],
      "metadata": {
        "id": "qyE1yPWn6h-1"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_versions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQBPMvwdYYI2",
        "outputId": "3d8f7a76-842d-4ebc-d108-68b29ba2821a"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+--------------+--------------------+-----------+--------------------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|    categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|     submitter|               title|update_date|            versions|             version|\n",
            "+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+--------------+--------------------+-----------+--------------------+--------------------+\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|        hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|ANL-HEP-PR-07-12|Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|        hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|ANL-HEP-PR-07-12|Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|{Tue, 24 Jul 2007...|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...| math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|            NULL|  Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...| math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|            NULL|  Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|{Sat, 13 Dec 2008...|\n",
            "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]|physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|            NULL|   Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|{Sun, 1 Apr 2007 ...|\n",
            "+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+--------------+--------------------+-----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to keep only version 1\n",
        "version_1_data = data_with_versions.filter(col(\"version.version\") == \"v1\")"
      ],
      "metadata": {
        "id": "g2aCgmGQ7O1T"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version_1_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peg5Pd50ZIWi",
        "outputId": "8e428c20-2211-4f24-936a-6294ee384ee8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|       categories|            comments|                 doi|       id|         journal-ref|             license|           report-no|         submitter|               title|update_date|            versions|             version|\n",
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------------+\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|           hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|    ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|    math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|                NULL|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]|   physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|                NULL|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|{Sun, 1 Apr 2007 ...|\n",
            "|  We show that a ...|        David Callan| [[Callan, David, ]]|          math.CO|            11 pages|                NULL|0704.0004|                NULL|                NULL|                NULL|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|  math.CA math.FA|                NULL|                NULL|0704.0005|Illinois J. Math....|                NULL|                NULL|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  We study the tw...|Y. H. Pong and C....|[[Pong, Y. H., ],...|cond-mat.mes-hall|6 pages, 4 figure...|10.1103/PhysRevA....|0704.0006|                NULL|                NULL|                NULL|      Yue Hin Pong|Bosonic character...| 2015-05-13|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  A rather non-st...|Alejandro Corichi...|[[Corichi, Alejan...|            gr-qc|16 pages, no figu...|10.1103/PhysRevD....|0704.0007|Phys.Rev.D76:0440...|                NULL|        IGPG-07/03-2| Alejandro Corichi|Polymer Quantum M...| 2008-11-26|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  A general formu...|     Damian C. Swift|[[Swift, Damian C...|cond-mat.mtrl-sci|   Minor corrections|   10.1063/1.2975338|0704.0008|Journal of Applie...|http://arxiv.org/...|LA-UR-07-2051, LL...|      Damian Swift|Numerical solutio...| 2009-02-05|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  We discuss the ...|Paul Harvey, Brun...|[[Harvey, Paul, ]...|         astro-ph|                NULL|      10.1086/518646|0704.0009|Astrophys.J.663:1...|                NULL|                NULL|       Paul Harvey|The Spitzer c2d S...| 2010-03-18|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  Partial cubes a...|  Sergei Ovchinnikov|[[Ovchinnikov, Se...|          math.CO|36 pages, 17 figures|                NULL|0704.0010|                NULL|                NULL|                NULL|Sergei Ovchinnikov|Partial cubes: st...| 2007-05-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  In this paper w...|Clifton Cunningha...|[[Cunningham, Cli...|  math.NT math.AG|14 pages; title c...|                NULL|0704.0011|                NULL|http://arxiv.org/...|                NULL|Clifton Cunningham|Computing genus 2...| 2008-08-20|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  Recently, Bruin...|         Dohoon Choi|  [[Choi, Dohoon, ]]|          math.NT|                NULL|                NULL|0704.0012|                NULL|                NULL|                NULL|       Dohoon Choi|Distribution of i...| 2007-05-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  Serre obtained ...|Dohoon Choi and Y...|[[Choi, Dohoon, ]...|          math.NT|                NULL|                NULL|0704.0013|                NULL|                NULL|                NULL|       Dohoon Choi|$p$-adic Limit of...| 2008-05-26|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  In this article...|        Koichi Fujii| [[Fujii, Koichi, ]]|  math.CA math.AT|  18 pages, 1 figure|                NULL|0704.0014|                NULL|                NULL|                NULL|      Koichi Fujii|Iterated integral...| 2009-09-29|[{Sun, 1 Apr 2007...|{Sun, 1 Apr 2007 ...|\n",
            "|  The pure spinor...|     Christian Stahn|[[Stahn, Christia...|           hep-th|22 pages; signs a...|10.1088/1126-6708...|0704.0015|  JHEP 0705:034,2007|                NULL|                NULL|   Christian Stahn|Fermionic superst...| 2009-11-13|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  In this work, w...|Chao-Hsi Chang, T...|[[Chang, Chao-Hsi...|           hep-ph|17 pages, 3 figur...|10.1088/0253-6102...|0704.0016|Commun.Theor.Phys...|                NULL|                NULL|           Li Tong|Lifetime of doubl...| 2008-12-18|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  Results from sp...|Nceba Mhlahlo, Da...|[[Mhlahlo, Nceba,...|         astro-ph|10 pages, 11 figu...|10.1111/j.1365-29...|0704.0017|Mon.Not.Roy.Astro...|                NULL|                NULL|     Nceba Mhlahlo|Spectroscopic Obs...| 2009-06-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  We give a presc...|  Andreas Gustavsson|[[Gustavsson, And...|           hep-th|20 pages, v2: an ...|                NULL|0704.0018|                NULL|                NULL|                NULL|Andreas Gustavsson|In quest of a gen...| 2007-05-23|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...|\n",
            "|  In this note we...|         Norio Konno|  [[Konno, Norio, ]]|  math.PR math.AG|6 pages, Journal-...|                NULL|0704.0019|RIMS Kokyuroku, N...|                NULL|                NULL|       Norio Konno|Approximation for...| 2007-06-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "|  The shape of th...|The BABAR Collabo...|[[The BABAR Colla...|           hep-ex|21 pages, 13 post...|10.1103/PhysRevD....|0704.0020|Phys.Rev.D76:0520...|                NULL|BABAR-PUB-07/015,...|   Patrick Roudeau|Measurement of th...| 2015-06-30|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...|\n",
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date, to_timestamp"
      ],
      "metadata": {
        "id": "lB4nRfwp7Gw5"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to_date() - Converts a pyspark.sql.Column into pyspark.sql.types.DateType using the optionally specified format."
      ],
      "metadata": {
        "id": "cZUczgmgAS2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the column has dates like Mon, 01 Jan 2023 12:34:56 +0000, the format string should be:\n",
        "\n",
        "EEE, dd MMM yyyy HH:mm:ss Z"
      ],
      "metadata": {
        "id": "EFIv8plVn3vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version_1_data.select(\"version.created\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9ad-qdWnoEp",
        "outputId": "3186cb78-b157-4416-e8f1-6ad5db76a4a3"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|created                      |\n",
            "+-----------------------------+\n",
            "|Mon, 2 Apr 2007 19:18:42 GMT |\n",
            "|Sat, 31 Mar 2007 02:26:18 GMT|\n",
            "|Sun, 1 Apr 2007 20:46:54 GMT |\n",
            "|Sat, 31 Mar 2007 03:16:14 GMT|\n",
            "|Mon, 2 Apr 2007 18:09:58 GMT |\n",
            "+-----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this format is actually `EEE, d MMM yyyy HH:mm:ss z`\n",
        "\n",
        "d is the day of the month (without leading zeros)"
      ],
      "metadata": {
        "id": "5d0HlVPtoInE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
      ],
      "metadata": {
        "id": "eGdGXpnqrYj9"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "not ideal but at least works..."
      ],
      "metadata": {
        "id": "_g-pwO3wrbvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the submission date and convert it to a date format\n",
        "# version_1_data = version_1_data.withColumn(\"submission_date\", to_date(col(\"version.created\"), \"EEE, dd MMM yyyy HH:mm:ss Z\"))\n",
        "\n",
        "\"\"\"\n",
        "version_1_data = version_1_data.withColumn(\n",
        "    \"submission_timestamp\",\n",
        "    to_timestamp(col(\"created\"), \"EEE, d MMM yyyy HH:mm:ss X\")\n",
        ")\n",
        "\n",
        "\n",
        "version_1_data = version_1_data.withColumn(\n",
        "    \"submission_date\",\n",
        "    to_date(col(\"version.created\"), \"EEE, d MMM yyyy HH:mm:ss X\")\n",
        ")\n",
        "\"\"\"\n",
        "# Apply the timestamp conversion using the correct pattern\n",
        "version_1_data = version_1_data.withColumn(\n",
        "    \"submission_timestamp\",\n",
        "    to_timestamp(col(\"version.created\"), \"EEE, d MMM yyyy HH:mm:ss z\")\n",
        ")\n",
        "\n",
        "# Extract only the date (if you need it)\n",
        "from pyspark.sql.functions import to_date\n",
        "version_1_data = version_1_data.withColumn(\n",
        "    \"submission_date\",\n",
        "    to_date(col(\"submission_timestamp\"))\n",
        ")\n",
        "\n",
        "# Verify the result\n",
        "version_1_data.select(\"version.created\", \"submission_date\").show(5, truncate=False)"
      ],
      "metadata": {
        "id": "XiqKSye-7E3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f7a1cf-1930-46ca-832b-a3ed8e5fc565"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+---------------+\n",
            "|created                      |submission_date|\n",
            "+-----------------------------+---------------+\n",
            "|Mon, 2 Apr 2007 19:18:42 GMT |2007-04-02     |\n",
            "|Sat, 31 Mar 2007 02:26:18 GMT|2007-03-31     |\n",
            "|Sun, 1 Apr 2007 20:46:54 GMT |2007-04-01     |\n",
            "|Sat, 31 Mar 2007 03:16:14 GMT|2007-03-31     |\n",
            "|Mon, 2 Apr 2007 18:09:58 GMT |2007-04-02     |\n",
            "+-----------------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version_1_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_yNOZwqPm5",
        "outputId": "65a2a49d-1bd1-4aae-9e00-ae98e233c254"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+\n",
            "|            abstract|             authors|      authors_parsed|     categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|         submitter|               title|update_date|            versions|             version|submission_timestamp|submission_date|\n",
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|         hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...| 2007-04-02 19:18:42|     2007-04-02|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|  math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|            NULL|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...| 2007-03-31 02:26:18|     2007-03-31|\n",
            "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]| physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|            NULL|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|{Sun, 1 Apr 2007 ...| 2007-04-01 20:46:54|     2007-04-01|\n",
            "|  We show that a ...|        David Callan| [[Callan, David, ]]|        math.CO|            11 pages|                NULL|0704.0004|                NULL|                NULL|            NULL|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...| 2007-03-31 03:16:14|     2007-03-31|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|math.CA math.FA|                NULL|                NULL|0704.0005|Illinois J. Math....|                NULL|            NULL|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...| 2007-04-02 18:09:58|     2007-04-02|\n",
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version_1_data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25V-aSwCmfbg",
        "outputId": "ae159591-2190-4428-bce3-418173dca2b7"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- abstract: string (nullable = true)\n",
            " |-- authors: string (nullable = true)\n",
            " |-- authors_parsed: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- comments: string (nullable = true)\n",
            " |-- doi: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- journal-ref: string (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            " |-- report-no: string (nullable = true)\n",
            " |-- submitter: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- update_date: string (nullable = true)\n",
            " |-- versions: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- created: string (nullable = true)\n",
            " |    |    |-- version: string (nullable = true)\n",
            " |-- version: struct (nullable = true)\n",
            " |    |-- created: string (nullable = true)\n",
            " |    |-- version: string (nullable = true)\n",
            " |-- submission_timestamp: timestamp (nullable = true)\n",
            " |-- submission_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_extract"
      ],
      "metadata": {
        "id": "fiZFAOOa7eW7"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6ZSEI5cVrlfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "regex_extract() - Extract a specific group matched by the Java regex regexp, from the specified string column. If the regex did not match, or the specified group did not match, an empty string is returned"
      ],
      "metadata": {
        "id": "juOLf8scAeYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the page count from the comments (assuming comments contain \"X pages\")\n",
        "version_1_data = version_1_data.withColumn(\"page_count\",\n",
        "                                           regexp_extract(col(\"comments\"),\n",
        "                                                          r\"(\\d+) pages\", 1).\n",
        "                                           cast(\"int\"))"
      ],
      "metadata": {
        "id": "WlSgp2TJ7dhN"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version_1_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5m0FbGlXTo",
        "outputId": "0372a5e2-00b1-48de-b41c-0f16b7310a6c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+----------+\n",
            "|            abstract|             authors|      authors_parsed|     categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|         submitter|               title|update_date|            versions|             version|submission_timestamp|submission_date|page_count|\n",
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+----------+\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|         hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...| 2007-04-02 19:18:42|     2007-04-02|        37|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|  math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|            NULL|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...| 2007-03-31 02:26:18|     2007-03-31|      NULL|\n",
            "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]| physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|            NULL|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|{Sun, 1 Apr 2007 ...| 2007-04-01 20:46:54|     2007-04-01|        23|\n",
            "|  We show that a ...|        David Callan| [[Callan, David, ]]|        math.CO|            11 pages|                NULL|0704.0004|                NULL|                NULL|            NULL|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|{Sat, 31 Mar 2007...| 2007-03-31 03:16:14|     2007-03-31|        11|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|math.CA math.FA|                NULL|                NULL|0704.0005|Illinois J. Math....|                NULL|            NULL|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|{Mon, 2 Apr 2007 ...| 2007-04-02 18:09:58|     2007-04-02|      NULL|\n",
            "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+--------------------+--------------------+---------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum"
      ],
      "metadata": {
        "id": "_3K_gmCnmtWI"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by submission_date and calculate total pages\n",
        "pages_per_day = (\n",
        "    version_1_data.groupBy(\"submission_date\")\n",
        "    .agg(_sum(\"page_count\").alias(\"total_pages\"))\n",
        ")"
      ],
      "metadata": {
        "id": "xOm0I2Qo9eSN"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg"
      ],
      "metadata": {
        "id": "vbSiFpcOApmv"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "avg() - Aggregate function: returns the average of the values in a group"
      ],
      "metadata": {
        "id": "qVeZ_uuUAy1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average number of pages per day\n",
        "average_pages_per_day = pages_per_day.select(avg(col(\"total_pages\")).alias(\"avg_pages_per_day\"))"
      ],
      "metadata": {
        "id": "m0V2SgG_9frM"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the result\n",
        "average_pages_per_day.show()"
      ],
      "metadata": {
        "id": "zP77a6fF9nFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6931ecbd-7d17-4ad2-9ae3-26bb927a7113"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "| avg_pages_per_day|\n",
            "+------------------+\n",
            "|1912.9052574427653|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cD5hiCgprqJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}