{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Azure RAG Workshop – Session 1**\n",
    "### Resource Creation: Document Intelligence, Azure AI Search, and Azure OpenAI\n",
    "\n",
    "Welcome to the first session of our **RAG (Retrieval Augmented Generation) Assistant** Workshop! \n",
    "\n",
    "In this notebook, we will:\n",
    "1. **Create and configure Azure resources** needed for our project:\n",
    "   - **Document Intelligence (Form Recognizer)** for document ingestion and text extraction.\n",
    "   - **Azure AI Search** (Cognitive Search) to store and query document embeddings.\n",
    "   - **Azure OpenAI** to leverage foundational language models for text generation and embeddings.\n",
    "\n",
    "2. **Show two approaches** for resource creation:\n",
    "   - **Using the Azure Portal** (manual UI steps).\n",
    "   - **Using the Azure Python SDK** (programmatic approach).\n",
    "\n",
    "3. **Discuss environment variables** for authentication and best practices in secure credential management.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Prerequisites**\n",
    "\n",
    "Before we dive into code, make sure you have the following in place:\n",
    "\n",
    "- **Azure Subscription** – You must have Contributor or Owner rights on at least one subscription.\n",
    "- **Azure CLI installed** (optional but helpful).\n",
    "- **Python 3.8+** with the following packages installed:\n",
    "  ```bash\n",
    "  pip install azure-identity azure-mgmt-resource azure-mgmt-cognitiveservices azure-search-documents\n",
    "  ```\n",
    "   Optionally, if you will interact directly with Azure OpenAI or Document Intelligence in your code, you may need:  \n",
    "\n",
    "  ```bash\n",
    "  pip install azure-ai-formrecognizer azure-openai\n",
    "  ```\n",
    "- **Jupyter Notebook environment** (e.g., JupyterLab, VSCode, or another environment supporting notebooks).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Environment Setup**\n",
    "We'll use environment variables to store sensitive information like Subscription ID or personal tokens. This ensures we don't hard-code credentials in our notebooks.\n",
    "\n",
    "### Example of environment variables to set locally\n",
    "\n",
    "- `AZURE_SUBSCRIPTION_ID`: Your Azure subscription ID.\n",
    "- `AZURE_CLIENT_ID`: If using a Service Principal or managed identity.\n",
    "- `AZURE_TENANT_ID`: Azure tenant ID.\n",
    "- `AZURE_CLIENT_SECRET`: If using a Service Principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load Environemment Variables\n",
    "load_dotenv(\".secrets/.env\")\n",
    "\n",
    "# Example of retrieving environment variables\n",
    "subscription_id = os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    "print(f\"Subscription ID: {subscription_id}\")\n",
    "tenant_id = os.environ.get(\"AZURE_TENANT_ID\")\n",
    "print(f\"Tenant ID: {tenant_id}\")\n",
    "\n",
    "# Quick check to ensure they are set\n",
    "if not subscription_id:\n",
    "    raise ValueError(\"AZURE_SUBSCRIPTION_ID environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centralized Secrets Management - If you're using a secret manager (like AWS Secrets Manager, Azure Key Vault, or HashiCorp Vault, Google Cloud Secret Manager HashiCorp Vault), you won't need .env files or the dotenv library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **3. Creating Azure Resources**\n",
    "We’ll create three main resources: **Document Intelligence (Form Recognizer)**, **Azure AI Search (Cognitive Search)**, and **Azure OpenAI**. We’ll demonstrate two methods: **Portal** and **Python SDK**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **3.1 Resource Names and Configuration**\n",
    "Let's define some variables (like resource group name, region, and unique resource names) to keep our code organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Adjust these variables as needed\n",
    "RESOURCE_GROUP_NAME = \"PMR Consulting\"\n",
    "LOCATION = \"westeurope\"  # or your preferred region\n",
    "YOUR_NAME = \"ricardo\"\n",
    "\n",
    "# Typically, resource names must be unique. \n",
    "# For demonstration, we append a short GUID segment:\n",
    "random_id = str(uuid.uuid4())[:8]\n",
    "\n",
    "DOCUMENT_INTELLIGENCE_NAME = f\"docintel-{random_id}-{YOUR_NAME}\"\n",
    "SEARCH_SERVICE_NAME = f\"search-{random_id}-{YOUR_NAME}\"\n",
    "OPENAI_SERVICE_NAME = f\"openai-{random_id}-{YOUR_NAME}\"\n",
    "\n",
    "print(\"Resource Group:\", RESOURCE_GROUP_NAME)\n",
    "print(\"Location:\", LOCATION)\n",
    "print(\"Document Intelligence (Form Recognizer):\", DOCUMENT_INTELLIGENCE_NAME)\n",
    "print(\"Search Service:\", SEARCH_SERVICE_NAME)\n",
    "print(\"OpenAI Service:\", OPENAI_SERVICE_NAME)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "eg. output:\n",
    "\n",
    "Resource Group: PMR Consulting\n",
    "Location: westeurope\n",
    "Document Intelligence (Form Recognizer): docintel-a89890c4-ricardo\n",
    "Search Service: search-a89890c4-ricardo\n",
    "OpenAI Service: openai-a89890c4-ricardo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Creating Resources via the Azure Portal (Manual Steps)**\n",
    "(You can skip to 3.3 if you only want the Python SDK approach.)\n",
    "\n",
    "1. **Create a Resource Group**\n",
    "   1. Log into Azure Portal.\n",
    "   2. Search for “Resource groups” in the top search bar.\n",
    "   3. Click “Create” and enter:\n",
    "     - **Subscription**: Select your subscription.\n",
    "     - **Resource group**: `PMR Consulting` (or chosen name)\n",
    "     - **Region**: `westeurope`.\n",
    "   4. Click “Review + Create” and then “Create”.\n",
    "   \n",
    "2. **Create Document Intelligence (Form Recognizer)**\n",
    "   1. In the Portal, search for \"Document Intelligence\" (previously “Form Recognizer” or “Cognitive Services”). \n",
    "   2. Click “Create” on \"Document Intelligence\".\n",
    "   3. Fill out:\n",
    "      - **Subscription**: Same subscription.\n",
    "      - **Resource group**: `PMR Consulting`.\n",
    "      - **Region**: `westeurope`.\n",
    "      - **Resource name**: `docintel-XXXXXX` (unique name).\n",
    "   4. Choose Pricing tier (e.g., “F0”).\n",
    "   5. Review, then click “Create”.\n",
    "\n",
    "\n",
    "3. **Create Azure AI Search (Cognitive Search)**\n",
    "   1. In the Portal, search for “Azure AI Search”.\n",
    "   2. Click “Create” and select your subscription and resource group.\n",
    "   3. Set “Search service name” to `search-XXXXXX` (unique name).\n",
    "   4. Select region `westeurope`, choose **Basic** or **Standard tier** (depending on your needs).\n",
    "   5. Click “Review + create” then “Create”.\n",
    "\n",
    "4. **Create Azure OpenAI**\n",
    "   1. In the Portal, search for “Azure OpenAI” (ensure you have access to Azure OpenAI).\n",
    "   2. Click “Create” under the Azure OpenAI pane.\n",
    "   3. Fill out the form (subscription, resource group, name, region).\n",
    "   4. **Pricing tier**: Choose one that matches your usage (e.g., “Standard”).\n",
    "   5. Click “Review + create” then “Create”.\n",
    "\n",
    "\n",
    "Once all resources are created, you can verify them in your resource group in the Portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **3.3 Creating Resources Programmatically (Azure CLI)**\n",
    "For a more automated, scriptable approach, we can use the Azure Python CLI to create the same resources.\n",
    "\n",
    "Just open up the terminal in the Azure portal (you can also locally authenticate an environement), and you can use Azure CLI to programmatically create resources.\n",
    "\n",
    "- Here is an example with the `Document Intelligence` resource.\n",
    "\n",
    "```bash\n",
    "# Create the Document Intelligence resource\n",
    "az cognitiveservices account create --name <your-resource-name> --resource-group <your-resource-group-name> --kind FormRecognizer --sku <Tier> --location <location> --yes\n",
    "\n",
    "# Get the endpoint for the Document Intelligence resource\n",
    "az cognitiveservices account show --name <your-resource-name> --resource-group \"<your-resource-group-name>\" --query \"properties.endpoint\"\n",
    "\n",
    "# Get the API Key for the Document Intelligence resource\n",
    "az cognitiveservices account keys list --name <your-resource-name> --resource-group \"<your-resource-group-name>\"\n",
    "```\n",
    "\n",
    "- With the replaced details, full commands here:\n",
    "\n",
    "```bash\n",
    "# Create the Document Intelligence resource\n",
    "az cognitiveservices account create --name sdk-docintel --resource-group DataAcademy --kind FormRecognizer --sku S0 --location westeurope --yes\n",
    "\n",
    "# Get the endpoint for the Document Intelligence resource\n",
    "az cognitiveservices account show --name \"sdk-docintel\" --resource-group \"DataAcademy\" --query \"properties.endpoint\"\n",
    "\n",
    "# Get the API Key for the Document Intelligence resource\n",
    "az cognitiveservices account keys list --name \"sdk-docintel\" --resource-group \"DataAcademy\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. Create an ingestion function with Langchain using Azure Document Intelligence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 - Create a text extraction function** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# Define a cross-platform file path\n",
    "file_path = Path(\"data\") / \"General FAQ.pdf\"\n",
    "# file_path = \"data/General FAQ.pdf\"\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "key = os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "loader = AzureAIDocumentIntelligenceLoader(\n",
    "    api_endpoint=endpoint, api_key=key, file_path=str(file_path), api_model=\"prebuilt-layout\"\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "   print(f\"Page Content: {document.page_content}\")\n",
    "   print(f\"Metadata: {document.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 - Create a text extraction function for a full folder** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_text_from_pdfs_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Extract text from all PDF documents located in a specified directory \n",
    "    using Azure Document Intelligence (Form Recognizer). \n",
    "    \n",
    "    :param directory_path: Path to the directory containing PDF files.\n",
    "    :return: A list of Document objects (LangChain Document type) from all PDF files.\n",
    "    \"\"\"\n",
    "    endpoint = os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "    key = os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "    if not endpoint:\n",
    "        raise ValueError(\"The environment variable 'AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT' is not set.\")\n",
    "    if not key:\n",
    "        raise ValueError(\"The environment variable 'AZURE_DOCUMENT_INTELLIGENCE_KEY' is not set.\")\n",
    "\n",
    "    all_documents = []\n",
    "\n",
    "    # Iterate over every file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file is a PDF\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Instantiate the loader for this PDF file\n",
    "            loader = AzureAIDocumentIntelligenceLoader(\n",
    "                api_endpoint=endpoint, \n",
    "                api_key=key, \n",
    "                file_path=file_path, \n",
    "                api_model=\"prebuilt-layout\"\n",
    "            )\n",
    "            # Load the documents from the current PDF\n",
    "            docs = loader.load()\n",
    "            # Accumulate the documents\n",
    "            all_documents.extend(docs)\n",
    "\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = extract_text_from_pdfs_in_directory(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for document in all_documents:\n",
    "   print(f\"Page {i}:\")  \n",
    "   print(document.page_content)\n",
    "   i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. Create a Search Index in Azure Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an Azure OpenAI account with a deployment of an embedding model\n",
    "azure_endpoint= os.environ.get(\"AZURE_OPENAI_API_EMBEDDING_ENDPOINT\")\n",
    "azure_openai_api_key= os.environ.get(\"AZURE_OPENAI_API_EMBEDDING_KEY\")\n",
    "azure_openai_api_version= \"2023-05-15\"\n",
    "azure_deployment= \"text-embedding-3-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up details for Azure Search\n",
    "vector_store_address = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "vector_store_password = os.environ.get(\"AZURE_SEARCH_ADMIN_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 - Create index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AzureOpenAIEmbeddings with an Azure account\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create Vector Store Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"langchain-vector-demo\"\n",
    "\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add Documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform Semantic Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "ss_result = vector_store.similarity_search(\n",
    "    query=\"What types of tires does AutoGrip manufacture? \",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss_result[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Delete Index (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.core.credentials import AzureKeyCredential\n",
    "# from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# service_endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "# index_name = \"langchain-vector-demo\"\n",
    "# key = os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]\n",
    "\n",
    "# # Delete Index\n",
    "# search_index_client = SearchIndexClient(service_endpoint, AzureKeyCredential(key))\n",
    "# search_index_client.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 - Create function for semantic similarity search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss_results_text(query, n_results):\n",
    "    # Instantiate the embeddings model\n",
    "    # Use AzureOpenAIEmbeddings with an Azure account\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-3-large\",\n",
    "        openai_api_version=\"2023-05-15\",\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_EMBEDDING_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_EMBEDDING_KEY\"),\n",
    "    )\n",
    "\n",
    "    # Instantiate the Vector Store\n",
    "    vector_store = AzureSearch(\n",
    "        azure_search_endpoint=os.environ.get(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "        azure_search_key=os.environ.get(\"AZURE_SEARCH_ADMIN_KEY\"),\n",
    "        index_name=\"langchain-vector-demo\",\n",
    "        embedding_function=embeddings.embed_query)\n",
    "    \n",
    "    ss_result = vector_store.similarity_search(\n",
    "        query=query,\n",
    "        k=n_results,\n",
    "        search_type=\"similarity\"\n",
    "        )\n",
    "    \n",
    "    final_result_string = \"\"\n",
    "\n",
    "    for document in ss_result:\n",
    "       final_result_string += document.page_content\n",
    "\n",
    "    return final_result_string, ss_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_result_string, full_results = get_ss_results_text(\"What types of tires does AutoGrip manufacture?\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Make Requests to a LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 - Instantiate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    openai_api_version=\"2024-12-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"Hello, world!\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 - Create a method for prompt interaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt call\n",
    "def llm_invoke(prompt):\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
    "        azure_deployment=\"gpt-4o\",\n",
    "        openai_api_version=\"2024-12-01-preview\",\n",
    "    )\n",
    "\n",
    "    return model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_invoke(\"who was Marie Curie?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **7. Final Orchestration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rag_chatbot():\n",
    "    \"\"\"\n",
    "    Runs a simple RAG-based chatbot in a Jupyter notebook cell.\n",
    "    Continues the conversation until the user types '\\quit'.\n",
    "    \n",
    "    Requirements:\n",
    "      - get_ss_results_text(query, n_results) -> returns (context_string, list_of_docs)\n",
    "      - llm_invoke(prompt) -> returns LLM-generated answer\n",
    "      \n",
    "    Workflow:\n",
    "      1. Prompt user for input query.\n",
    "      2. Pass the user query to get_ss_results_text() to retrieve context.\n",
    "      3. Build a prompt that includes conversation history + context + user query.\n",
    "      4. Call llm_invoke() to get the model's answer.\n",
    "      5. Append user query & model answer to conversation history.\n",
    "      6. Repeat until the user types '\\quit'.\n",
    "    \"\"\"\n",
    "    \n",
    "    conversation_memory = \"\"  # Will store conversation in text form\n",
    "    print(\"Welcome to the RAG Chatbot! Type '\\\\quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        # 1) Prompt user for input\n",
    "        user_query = input(\"User: \")\n",
    "        \n",
    "        # Check if user wants to exit\n",
    "        if user_query.strip().lower() == \"\\\\quit\":\n",
    "            print(\"Exiting the chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Print User query\n",
    "        print(f\"User: {user_query}\\n\")\n",
    "\n",
    "        # 2) Retrieve semantic search context\n",
    "        context_string, docs = get_ss_results_text(user_query, n_results=3)\n",
    "        \n",
    "        # 3) Build a prompt that incorporates the conversation so far + new user query + context\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful AI assistant. Use the conversation history, the user's new question, and any provided context to craft your answer.\n",
    "        \n",
    "        Conversation so far:\n",
    "        {conversation_memory}\n",
    "\n",
    "        Relevant context from knowledge base:\n",
    "        {context_string}\n",
    "\n",
    "        Now the user asks: {user_query}\n",
    "\n",
    "        Answer in a helpful, concise manner:\n",
    "        \"\"\"\n",
    "        \n",
    "        # 4) Call the LLM with the combined prompt\n",
    "        answer = llm_invoke(prompt)\n",
    "        \n",
    "        # 5) Update conversation memory\n",
    "        conversation_memory += f\"User: {user_query}\\nAssistant: {answer}\\n\"\n",
    "        \n",
    "        # 6) Print the answer for the user\n",
    "        print(f\"Assistant: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
