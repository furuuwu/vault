{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import certifi\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top-level module logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create a /logs directory if it doesn't exist\n",
    "log_directory = 'logs'\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "# Define the log file path\n",
    "log_file = os.path.join(log_directory, 'data_extraction.log')\n",
    "\n",
    "# Set up logging to a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),  # Log to a file\n",
    "        logging.StreamHandler()  # Also log to console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_data_from_parquet(parquet_file_name):\n",
    "    try:\n",
    "        df_parquet = pd.read_parquet(parquet_file_name)\n",
    "        logger.info(f'{parquet_file_name} : extracted {df_parquet.shape[0]} records from the parquet file')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{parquet_file_name} : exception {e} encountered while extracting the parquet file')\n",
    "        df_parquet = pd.DataFrame()\n",
    "    return df_parquet\n",
    "\n",
    "\n",
    "def source_data_from_csv(csv_file_name):\n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_name)\n",
    "        logger.info(f'{csv_file_name} : extracted {df_csv.shape[0]} records from the CSV file')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{csv_file_name} : exception {e} encountered while extracting the CSV file')\n",
    "        df_csv = pd.DataFrame()\n",
    "    return df_csv\n",
    "\n",
    "\n",
    "def source_data_from_api(api_endpoint):\n",
    "    try:\n",
    "        # Create a PoolManager to handle HTTP requests\n",
    "        http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "        api_response = http.request('GET', api_endpoint)\n",
    "        api_status = api_response.status\n",
    "        if api_status == 200:\n",
    "            logger.info(f'{api_status} - OK: while invoking the API {api_endpoint}')\n",
    "            data = json.loads(api_response.data.decode('utf-8'))\n",
    "            df_api = pd.json_normalize(data)\n",
    "            logger.info(f'{api_endpoint} : extracted {df_api.shape[0]} records from the API')\n",
    "        else:\n",
    "            logger.error(f'{api_status} - error: while invoking the API {api_endpoint}')\n",
    "            df_api = pd.DataFrame()  # Fixed typo: `pd.Dataframe()` to `pd.DataFrame()`\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Exception {e} encountered while reading data from the API: {api_endpoint}')\n",
    "        df_api = pd.DataFrame()\n",
    "    return df_api\n",
    "\n",
    "\n",
    "def source_data_from_table(db_name, table_name):\n",
    "    try:\n",
    "        with sqlite3.connect(db_name) as conn:\n",
    "            df_table = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "            logger.info(f'{db_name} : read {df_table.shape[0]} records from the table: {table_name}')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{db_name} : exception {e} encountered while reading data from the table: {table_name}')\n",
    "        df_table = pd.DataFrame()\n",
    "    return df_table\n",
    "\n",
    "\n",
    "def source_data_from_webpage(web_page_url, matching_keyword):\n",
    "    try:\n",
    "        df_html = pd.read_html(web_page_url, match=matching_keyword)\n",
    "        df_html = df_html[0]  # Extract the first matching table\n",
    "        logger.info(f'{web_page_url} : read {df_html.shape[0]} records from the webpage')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{web_page_url} : exception {e} encountered while reading data from the webpage')\n",
    "        df_html = pd.DataFrame()\n",
    "    return df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    parquet_file_name = \"data/yellow_tripdata_2022-01.parquet\"\n",
    "    csv_file_name = \"data/h9gi-nx95.csv\"\n",
    "    api_endpoint = \"https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500\"\n",
    "    db_name = \"movies.sqlite\"\n",
    "    table_name = \"movies\"\n",
    "    web_page_url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    matching_keyword = \"by country\"\n",
    "\n",
    "    # Extract data from all source systems\n",
    "    df_parquet, df_csv, df_api, df_table, df_html = (\n",
    "        source_data_from_parquet(parquet_file_name),\n",
    "        source_data_from_csv(csv_file_name),\n",
    "        source_data_from_api(api_endpoint),\n",
    "        source_data_from_table(db_name, table_name),\n",
    "        source_data_from_webpage(web_page_url, matching_keyword),\n",
    "    )\n",
    "    return df_parquet, df_csv, df_api, df_table, df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 17:26:36,351 - INFO - data/yellow_tripdata_2022-01.parquet : extracted 2463931 records from the parquet file\n",
      "2025-02-04 17:26:36,360 - INFO - data/h9gi-nx95.csv : extracted 500 records from the CSV file\n",
      "2025-02-04 17:26:38,020 - INFO - 200 - OK: while invoking the API https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500\n",
      "2025-02-04 17:26:38,033 - INFO - https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500 : extracted 500 records from the API\n",
      "2025-02-04 17:26:38,046 - INFO - movies.sqlite : read 5 records from the table: movies\n",
      "2025-02-04 17:26:38,638 - INFO - https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal) : read 210 records from the webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet DataFrame:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
      "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
      "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
      "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
      "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           3.80         1.0                  N           142           236   \n",
      "1           2.10         1.0                  N           236            42   \n",
      "2           0.97         1.0                  N           166           166   \n",
      "3           1.09         1.0                  N           114            68   \n",
      "4           4.30         1.0                  N            68           163   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         14.5    3.0      0.5        3.65           0.0   \n",
      "1             1          8.0    0.5      0.5        4.00           0.0   \n",
      "2             1          7.5    0.5      0.5        1.76           0.0   \n",
      "3             2          8.0    0.5      0.5        0.00           0.0   \n",
      "4             1         23.5    0.5      0.5        3.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "0                    0.3         21.95                   2.5          0.0  \n",
      "1                    0.3         13.30                   0.0          0.0  \n",
      "2                    0.3         10.56                   0.0          0.0  \n",
      "3                    0.3         11.80                   2.5          0.0  \n",
      "4                    0.3         30.30                   2.5          0.0  \n",
      "\n",
      "CSV DataFrame:\n",
      "                crash_date crash_time   borough  zip_code  latitude  \\\n",
      "0  2021-09-11T00:00:00.000       2:39       NaN       NaN       NaN   \n",
      "1  2022-03-26T00:00:00.000      11:45       NaN       NaN       NaN   \n",
      "2  2023-11-01T00:00:00.000       1:29  BROOKLYN   11230.0  40.62179   \n",
      "3  2022-06-29T00:00:00.000       6:55       NaN       NaN       NaN   \n",
      "4  2022-09-21T00:00:00.000      13:21       NaN       NaN       NaN   \n",
      "\n",
      "   longitude                       location           on_street_name  \\\n",
      "0        NaN                            NaN    WHITESTONE EXPRESSWAY   \n",
      "1        NaN                            NaN  QUEENSBORO BRIDGE UPPER   \n",
      "2 -73.970024  \\n,  \\n(40.62179, -73.970024)            OCEAN PARKWAY   \n",
      "3        NaN                            NaN       THROGS NECK BRIDGE   \n",
      "4        NaN                            NaN          BROOKLYN BRIDGE   \n",
      "\n",
      "  off_street_name cross_street_name  ...  contributing_factor_vehicle_2  \\\n",
      "0       20 AVENUE               NaN  ...                    Unspecified   \n",
      "1             NaN               NaN  ...                            NaN   \n",
      "2        AVENUE K               NaN  ...                    Unspecified   \n",
      "3             NaN               NaN  ...                    Unspecified   \n",
      "4             NaN               NaN  ...                    Unspecified   \n",
      "\n",
      "   contributing_factor_vehicle_3  contributing_factor_vehicle_4  \\\n",
      "0                            NaN                            NaN   \n",
      "1                            NaN                            NaN   \n",
      "2                    Unspecified                            NaN   \n",
      "3                            NaN                            NaN   \n",
      "4                            NaN                            NaN   \n",
      "\n",
      "   contributing_factor_vehicle_5  collision_id  \\\n",
      "0                            NaN       4455765   \n",
      "1                            NaN       4513547   \n",
      "2                            NaN       4675373   \n",
      "3                            NaN       4541903   \n",
      "4                            NaN       4566131   \n",
      "\n",
      "                    vehicle_type_code1  vehicle_type_code2  \\\n",
      "0                                Sedan               Sedan   \n",
      "1                                Sedan                 NaN   \n",
      "2                                Moped               Sedan   \n",
      "3                                Sedan       Pick-up Truck   \n",
      "4  Station Wagon/Sport Utility Vehicle                 NaN   \n",
      "\n",
      "   vehicle_type_code_3 vehicle_type_code_4 vehicle_type_code_5  \n",
      "0                  NaN                 NaN                 NaN  \n",
      "1                  NaN                 NaN                 NaN  \n",
      "2                Sedan                 NaN                 NaN  \n",
      "3                  NaN                 NaN                 NaN  \n",
      "4                  NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "API DataFrame:\n",
      "                crash_date crash_time           on_street_name  \\\n",
      "0  2021-09-11T00:00:00.000       2:39    WHITESTONE EXPRESSWAY   \n",
      "1  2022-03-26T00:00:00.000      11:45  QUEENSBORO BRIDGE UPPER   \n",
      "2  2023-11-01T00:00:00.000       1:29            OCEAN PARKWAY   \n",
      "3  2022-06-29T00:00:00.000       6:55       THROGS NECK BRIDGE   \n",
      "4  2022-09-21T00:00:00.000      13:21          BROOKLYN BRIDGE   \n",
      "\n",
      "  off_street_name number_of_persons_injured number_of_persons_killed  \\\n",
      "0       20 AVENUE                         2                        0   \n",
      "1             NaN                         1                        0   \n",
      "2        AVENUE K                         1                        0   \n",
      "3             NaN                         0                        0   \n",
      "4             NaN                         0                        0   \n",
      "\n",
      "  number_of_pedestrians_injured number_of_pedestrians_killed  \\\n",
      "0                             0                            0   \n",
      "1                             0                            0   \n",
      "2                             0                            0   \n",
      "3                             0                            0   \n",
      "4                             0                            0   \n",
      "\n",
      "  number_of_cyclist_injured number_of_cyclist_killed  ...  \\\n",
      "0                         0                        0  ...   \n",
      "1                         0                        0  ...   \n",
      "2                         0                        0  ...   \n",
      "3                         0                        0  ...   \n",
      "4                         0                        0  ...   \n",
      "\n",
      "  contributing_factor_vehicle_3 vehicle_type_code_3 location.latitude  \\\n",
      "0                           NaN                 NaN               NaN   \n",
      "1                           NaN                 NaN               NaN   \n",
      "2                   Unspecified               Sedan          40.62179   \n",
      "3                           NaN                 NaN               NaN   \n",
      "4                           NaN                 NaN               NaN   \n",
      "\n",
      "  location.longitude                             location.human_address  \\\n",
      "0                NaN                                                NaN   \n",
      "1                NaN                                                NaN   \n",
      "2         -73.970024  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
      "3                NaN                                                NaN   \n",
      "4                NaN                                                NaN   \n",
      "\n",
      "  cross_street_name contributing_factor_vehicle_4 vehicle_type_code_4  \\\n",
      "0               NaN                           NaN                 NaN   \n",
      "1               NaN                           NaN                 NaN   \n",
      "2               NaN                           NaN                 NaN   \n",
      "3               NaN                           NaN                 NaN   \n",
      "4               NaN                           NaN                 NaN   \n",
      "\n",
      "  contributing_factor_vehicle_5 vehicle_type_code_5  \n",
      "0                           NaN                 NaN  \n",
      "1                           NaN                 NaN  \n",
      "2                           NaN                 NaN  \n",
      "3                           NaN                 NaN  \n",
      "4                           NaN                 NaN  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Table DataFrame:\n",
      "   id                     title   genre  year  rating\n",
      "0   1                 Inception  Sci-Fi  2010     8.8\n",
      "1   2           The Dark Knight  Action  2008     9.0\n",
      "2   3              Interstellar  Sci-Fi  2014     8.6\n",
      "3   4              Pulp Fiction   Crime  1994     8.9\n",
      "4   5  The Shawshank Redemption   Drama  1994     9.3\n",
      "\n",
      "HTML DataFrame:\n",
      "  Country/Territory IMF[1][13]            World Bank[14]             \\\n",
      "  Country/Territory   Forecast       Year       Estimate       Year   \n",
      "0             World  115494312       2025      105435540       2023   \n",
      "1     United States   30337162       2025       27360935       2023   \n",
      "2             China   19534894  [n 1]2025       17794782  [n 3]2023   \n",
      "3           Germany    4921563       2025        4456081       2023   \n",
      "4             Japan    4389326       2025        4212945       2023   \n",
      "\n",
      "  United Nations[15]             \n",
      "            Estimate       Year  \n",
      "0          100834796       2022  \n",
      "1           25744100       2022  \n",
      "2           17963170  [n 1]2022  \n",
      "3            4076923       2022  \n",
      "4            4232173       2022  \n"
     ]
    }
   ],
   "source": [
    "# Call the function to test and log outputs\n",
    "if __name__ == \"__main__\":\n",
    "    df_parquet, df_csv, df_api, df_table, df_html = extract_data()\n",
    "\n",
    "    # Print previews\n",
    "    print(\"Parquet DataFrame:\")\n",
    "    print(df_parquet.head())\n",
    "    print(\"\\nCSV DataFrame:\")\n",
    "    print(df_csv.head())\n",
    "    print(\"\\nAPI DataFrame:\")\n",
    "    print(df_api.head())\n",
    "    print(\"\\nTable DataFrame:\")\n",
    "    print(df_table.head())\n",
    "    print(\"\\nHTML DataFrame:\")\n",
    "    print(df_html.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-DLmBe1Fh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
